{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_setosa = pd.read_csv(\"df_setosa\", sep=',')\n",
    "dataset_versicolor = pd.read_csv(\"df_versicolor\", sep=',')\n",
    "dataset_virginica = pd.read_csv(\"df_virginica\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_setosa_train = dataset_setosa.drop('class', axis=1, inplace=False)\n",
    "df_setosa_class = dataset_setosa[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_versicolor_train = dataset_versicolor.drop('class', axis=1, inplace=False)\n",
    "df_versicolor_class = dataset_versicolor[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_virginica_train = dataset_virginica.drop('class', axis=1, inplace=False)\n",
    "df_virginica_class = dataset_virginica[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron_simples():\n",
    "    \n",
    "    # FUNÇÃO __INIT__: primeira função que vai rodar quando eu instanciar a classe\n",
    "    # Método construtor de objetos. Self receberá a instância criada\n",
    "    def __init__(self, amostras_entrada, saidas, taxa_aprendizado=0.05, epocas=200, bias=-1):\n",
    "        self.amostras_entrada = amostras_entrada\n",
    "        self.saidas = saidas\n",
    "        self.taxa_aprendizado = taxa_aprendizado\n",
    "        self.epocas = epocas\n",
    "        self.bias = bias\n",
    "        self.num_amostras = len(amostras_entrada) # número de padrões do meu dataset\n",
    "        self.num_atributos = len(amostras_entrada[0]) # número de colunas do mue dataset\n",
    "        self.vetor_pesos = []\n",
    "        \n",
    "    def treino_rede(self):\n",
    "        \n",
    "        # Insiro o valor de bias/viés na posição zero para cada padrão da minha lista de amostras_entrada\n",
    "        for amostra in self.amostras_entrada:\n",
    "            amostra.insert(0, self.bias)\n",
    "            \n",
    "        # Gera valores aleatórios entre 0 e 1 para compor o vetor de pesos, do mesmo tamanho do número de colunas\n",
    "        for k in range(self.num_atributos):\n",
    "            self.vetor_pesos.append(random.random())\n",
    "        \n",
    "        # Insere o bias na posição zero do vetor de pesos\n",
    "        self.vetor_pesos.insert(0, self.bias)\n",
    "        \n",
    "        num_epocas = 0 # Inicializa a contagem de épocas\n",
    "        sum_erros = []\n",
    "        #sum_epocas = []\n",
    "        \n",
    "        while True:\n",
    "        \n",
    "            # Inicializa a variável erro, para poder ser testada ao final do loop. Se continuar falso, não houve mais erro\n",
    "            erro = False\n",
    "            sum_erros_epoca = 0\n",
    "            \n",
    "            for i in range(self.num_amostras):\n",
    "                u = 0 # Inicializa a função de ativação\n",
    "                \n",
    "                for j in range(self.num_atributos + 1): # +1 pelo fato de ter adicionado o valor do bias\n",
    "                    u += self.vetor_pesos[j] * self.amostras_entrada[i][j] # Executa o somatório WiXi\n",
    "                    \n",
    "                y_saida = self.valor_saida(u) # função degrau sobre o valor da função de ativação\n",
    "                \n",
    "                if y_saida != self.saidas[i]: \n",
    "                    erro_true = self.saidas[i] - y_saida # e = d - y\n",
    "                    sum_erros_epoca += abs(erro_true)\n",
    "                    \n",
    "                    for m in range(self.num_atributos + 1): # se há erro, atualiza o vetor de pesos\n",
    "                        self.vetor_pesos[m] = self.vetor_pesos[m] + self.taxa_aprendizado * erro_true * self.amostras_entrada[i][m]\n",
    "                        \n",
    "                    erro = True # se houve erro, continua true/no loop\n",
    "            \n",
    "            sum_erros.append(sum_erros_epoca)\n",
    "            #sum_epocas.append(num_epocas)\n",
    "            num_epocas += 1 # incrementa o número de épocas\n",
    "            \n",
    "            # Condição de saída: caso erro continue False após o teste com o real ou o numero de epocas estoure\n",
    "            if not erro or num_epocas >= self.epocas:\n",
    "                #print(num_epocas)\n",
    "                break\n",
    "                \n",
    "        return sum_erros\n",
    "        \n",
    "    def teste_rede(self, new_amostras): # Função para testar novas amostras\n",
    "        \n",
    "        new_amostras.insert(0, self.bias)\n",
    "        u = 0\n",
    "        \n",
    "        for i in range(self.num_atributos + 1):\n",
    "            u += self.vetor_pesos[i] * new_amostras[i]\n",
    "            \n",
    "        y_saida = self.valor_saida(u)\n",
    "        return y_saida\n",
    "        \n",
    "        \n",
    "    def valor_saida(self, u):\n",
    "        \n",
    "        if u>0:\n",
    "            return 1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_test(train_data, class_data, test_size, n_iter, class_var):\n",
    "    \n",
    "    acc_final = []\n",
    "    std_final = []\n",
    "    pred = []\n",
    "    conj_test = []\n",
    "\n",
    "    for rep in range(1 , n_iter + 1):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(train_data,class_data, \n",
    "                                                            test_size=test_size, shuffle=True)\n",
    "        print(X_train)\n",
    "        print(X_test)\n",
    "        conj_test.append([X_test])\n",
    "\n",
    "        amostras = X_train.values.tolist()\n",
    "        saidas = y_train.values.tolist()\n",
    "        new_amotras = X_test.values.tolist()\n",
    "        amostra_teste = y_test.values.tolist()\n",
    "\n",
    "        rede = Perceptron_simples(amostras, saidas)\n",
    "        J = rede.treino_rede()\n",
    "        \n",
    "        epoch = np.linspace(1,len(J),len(J))\n",
    "        %matplotlib inline\n",
    "        plt.figure()\n",
    "        plt.plot(epoch, J)\n",
    "        plt.xlabel('Época')\n",
    "        plt.ylabel('Somatório do Erro')\n",
    "        plt.title('Gráfico de Convergência - Perceptron Simples')\n",
    "        plt.show()\n",
    "\n",
    "        classe_predita = []\n",
    "\n",
    "        for pd in range(len(new_amotras)):\n",
    "            y = rede.teste_rede(new_amotras[pd])\n",
    "            classe_predita.append(y)\n",
    "            #print(\"Esperado=%d, Predito=%d\" % (amostra_teste[pd], y))\n",
    "\n",
    "        pred.append([classe_predita])\n",
    "        plot_confusion_matrix(amostra_teste, classe_predita, classes=['Não-{}'.format(class_var), class_var],\n",
    "                     title='Matriz de Confusão');\n",
    "        \n",
    "        acc = metrics.accuracy_score(amostra_teste, classe_predita)\n",
    "        std = np.sqrt(abs(metrics.explained_variance_score(amostra_teste, classe_predita)))\n",
    "\n",
    "        print(\"Realização {}: Tx. Acerto = {}\".format(rep, acc))\n",
    "        acc_final.append(acc)\n",
    "        std_final.append(std)\n",
    "\n",
    "    acc_real = np.mean(acc_final)\n",
    "    std_real = np.mean(std_final)\n",
    "    print(\"\\nAcurácia Final = {}, Desvio Padrão Final = {}\" .format(acc_real, std_real))\n",
    "    \n",
    "    return rede, pred, conj_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.BuGn):\n",
    "\n",
    "    # Computa a matriz de confusão\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           \n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='Real / Esperado',\n",
    "           xlabel='Predito')\n",
    "\n",
    "    # Rotaciona os labels\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    normalize = False\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_test(df_versicolor_train, df_versicolor_class, test_size=0.25, n_iter=20, class_var='Versicolor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_test(df_virginica_train, df_virginica_class, test_size=0.25, n_iter=20, class_var='Virginica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_test(df_setosa_train, df_setosa_class, test_size=0.25, n_iter=20, class_var='Setosa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REALIZAÇÕES - CONJUNTO DE DADOS ARTIFICIAL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_art_1 = pd.read_csv(\"artificial_1.csv\", sep=';')\n",
    "dataset_art_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_art_train = dataset_art_1.drop('classe', axis=1, inplace=False)\n",
    "df_art_class = dataset_art_1[\"classe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_art_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_art_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, pred, cj_te = data_test(df_art_train, df_art_class, test_size=0.3, n_iter=20, class_var='Zero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPERFÍCIE DE DECISÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_surface(pred_points, conj_te, n_rep):\n",
    "    \n",
    "    pred_pt = pred_points[n_rep][0]\n",
    "    \n",
    "    plt_x = conj_te[n_rep][0].values[:,0]\n",
    "    plt_y = conj_te[n_rep][0].values[:,1]\n",
    "    \n",
    "    plt.scatter(plt_x, plt_y, c=pred[n_rep][0], marker='s', s=100)\n",
    "    plt.xticks(np.arange(-0.3, 1.3, step=0.3))\n",
    "    plt.yticks(np.arange(-0.3, 1.3, step=0.3))\n",
    "    plt.xlabel(\"X1 Points\", fontsize=18);\n",
    "    plt.ylabel(\"X2 Points\", fontsize=18);\n",
    "    plt.grid()\n",
    "    plt.title(\"Superfície de Decisão - Realização {}\".format(n_rep + 1), fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "decision_surface(pred, cj_te, n_rep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe_predita = []\n",
    "\n",
    "for i in np.arange(0,1.05,0.05):\n",
    "    for k in np.arange(0,1.05,0.05):\n",
    "        par = [i,k]\n",
    "        y = model.teste_rede(par)\n",
    "        classe_predita.append([par[1], par[2], y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = []\n",
    "x2 = []\n",
    "cl = []\n",
    "\n",
    "for i in range(0, len(classe_predita)):\n",
    "    plt_x = classe_predita[i][0]\n",
    "    plt_y = classe_predita[i][1]\n",
    "    classe = classe_predita[i][2]\n",
    "    x1.append(plt_x)\n",
    "    x2.append(plt_y)\n",
    "    cl.append(classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x1, x2, c=cl, marker='s', s=30)\n",
    "plt.xticks(np.arange(-0.1, 1.2, step=0.2))\n",
    "plt.yticks(np.arange(-0.1, 1.2, step=0.2))\n",
    "plt.xlabel(\"X1 Points\", fontsize=18);\n",
    "plt.ylabel(\"X2 Points\", fontsize=18);\n",
    "plt.title(\"Superfície de Decisão - Conjunto Geral\", fontsize=17);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
